{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI1zCzgsef34"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_83cEYgef36"
      },
      "source": [
        "\n",
        "[Learn the Basics](intro.html) ||\n",
        "[Quickstart](quickstart_tutorial.html) ||\n",
        "[Tensors](tensorqs_tutorial.html) ||\n",
        "[Datasets & DataLoaders](data_tutorial.html) ||\n",
        "[Transforms](transforms_tutorial.html) ||\n",
        "**Build Model** ||\n",
        "[Autograd](autogradqs_tutorial.html) ||\n",
        "[Optimization](optimization_tutorial.html) ||\n",
        "[Save & Load Model](saveloadrun_tutorial.html)\n",
        "\n",
        "# Build the Neural Network\n",
        "\n",
        "Neural networks comprise of layers/modules that perform operations on data.\n",
        "The [torch.nn](https://pytorch.org/docs/stable/nn.html) namespace provides all the building blocks you need to\n",
        "build your own neural network. Every module in PyTorch subclasses the [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n",
        "A neural network is a module itself that consists of other modules (layers). This nested structure allows for\n",
        "building and managing complex architectures easily.\n",
        "\n",
        "In the following sections, we'll build a neural network to classify images in the FashionMNIST dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yncLQYt5ef38"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewEMjNJ1ef38"
      },
      "source": [
        "## Get Device for Training\n",
        "We want to be able to train our model on a hardware accelerator like the GPU,\n",
        "if it is available. Let's check to see if\n",
        "[torch.cuda](https://pytorch.org/docs/stable/notes/cuda.html) is available, else we\n",
        "continue to use the CPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-GBsnvjef39",
        "outputId": "97b75781-b89c-489b-e83d-9ff69292ff5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQfxk-Paef39"
      },
      "source": [
        "## Define the Class\n",
        "We define our neural network by subclassing ``nn.Module``, and\n",
        "initialize the neural network layers in ``__init__``. Every ``nn.Module`` subclass implements\n",
        "the operations on input data in the ``forward`` method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVod8OCOef39"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128,10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdvuWJ-uef3-"
      },
      "source": [
        "We create an instance of ``NeuralNetwork``, and move it to the ``device``, and print\n",
        "its structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odTWv5Lref3-",
        "outputId": "28706197-be5d-4653-87e8-7688beec1c52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PopwJu-Kef3-"
      },
      "source": [
        "To use the model, we pass it the input data. This executes the model's ``forward``,\n",
        "along with some [background operations](https://github.com/pytorch/pytorch/blob/270111b7b611d174967ed204776985cefca9c144/torch/nn/modules/module.py#L866).\n",
        "Do not call ``model.forward()`` directly!\n",
        "\n",
        "Calling the model on the input returns a 2-dimensional tensor with dim=0 corresponding to each output of 10 raw predicted values for each class, and dim=1 corresponding to the individual values of each output.  .\n",
        "We get the prediction probabilities by passing it through an instance of the ``nn.Softmax`` module.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcBh6iXHef3-",
        "outputId": "710fdfc9-5106-4d31-e98e-320daf5a48d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([0], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzCPLN5Gef3-"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFuXr7R5ef3_"
      },
      "source": [
        "## Model Layers\n",
        "\n",
        "Let's break down the layers in the FashionMNIST model. To illustrate it, we\n",
        "will take a sample minibatch of 3 images of size 28x28 and see what happens to it as\n",
        "we pass it through the network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icMjV8cuef4A",
        "outputId": "f579ad12-5973-499e-c705-89ee86feaedf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "input_image = torch.rand(3,28,28)\n",
        "print(input_image.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXyMKiJAef4A"
      },
      "source": [
        "### nn.Flatten\n",
        "We initialize the [nn.Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)\n",
        "layer to convert each 2D 28x28 image into a contiguous array of 784 pixel values (\n",
        "the minibatch dimension (at dim=0) is maintained).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfMt8rpBef4A",
        "outputId": "d7ddc7e8-9904-4d84-9aa8-fd87ca02cc7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ],
      "source": [
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyZg41LKef4B"
      },
      "source": [
        "### nn.Linear\n",
        "The [linear layer](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
        "is a module that applies a linear transformation on the input using its stored weights and biases.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAAZQWUqef4B",
        "outputId": "d1dc7aed-58e9-4e77-80fe-0a9e7b7ea506",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20])\n"
          ]
        }
      ],
      "source": [
        "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObdU5MFref4B"
      },
      "source": [
        "### nn.ReLU\n",
        "Non-linear activations are what create the complex mappings between the model's inputs and outputs.\n",
        "They are applied after linear transformations to introduce *nonlinearity*, helping neural networks\n",
        "learn a wide variety of phenomena.\n",
        "\n",
        "In this model, we use [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) between our\n",
        "linear layers, but there's other activations to introduce non-linearity in your model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_48gk-Gef4B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f695e99-572f-4a40-df85-eab02c0e20d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[ 0.1026, -0.3919,  0.0649,  0.2469,  0.4117, -0.3635,  0.0927, -0.5304,\n",
            "         -0.1220, -0.1270,  0.3949,  0.2691,  0.1085, -0.3105,  0.0251, -0.1254,\n",
            "         -0.5252,  0.4762,  0.5091, -0.0191],\n",
            "        [ 0.1939, -0.2049, -0.1350,  0.0938,  0.0328, -0.4518,  0.2389, -0.3866,\n",
            "         -0.0706, -0.0412,  0.5165,  0.1536,  0.2423, -0.5435,  0.0920,  0.0080,\n",
            "         -0.5454,  0.2494,  0.3977,  0.3498],\n",
            "        [-0.1416, -0.2453, -0.0153,  0.1237,  0.3774, -0.5513, -0.1275, -0.4407,\n",
            "         -0.1481,  0.1853, -0.0114,  0.3752,  0.0728, -0.1611,  0.2823, -0.0491,\n",
            "         -0.4741,  0.1429,  0.5152,  0.1056]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.1026, 0.0000, 0.0649, 0.2469, 0.4117, 0.0000, 0.0927, 0.0000, 0.0000,\n",
            "         0.0000, 0.3949, 0.2691, 0.1085, 0.0000, 0.0251, 0.0000, 0.0000, 0.4762,\n",
            "         0.5091, 0.0000],\n",
            "        [0.1939, 0.0000, 0.0000, 0.0938, 0.0328, 0.0000, 0.2389, 0.0000, 0.0000,\n",
            "         0.0000, 0.5165, 0.1536, 0.2423, 0.0000, 0.0920, 0.0080, 0.0000, 0.2494,\n",
            "         0.3977, 0.3498],\n",
            "        [0.0000, 0.0000, 0.0000, 0.1237, 0.3774, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.1853, 0.0000, 0.3752, 0.0728, 0.0000, 0.2823, 0.0000, 0.0000, 0.1429,\n",
            "         0.5152, 0.1056]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSoZQtm1ef4B"
      },
      "source": [
        "### nn.Sequential\n",
        "[nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) is an ordered\n",
        "container of modules. The data is passed through all the modules in the same order as defined. You can use\n",
        "sequential containers to put together a quick network like ``seq_modules``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5Ami5quef4B"
      },
      "outputs": [],
      "source": [
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xdgcC1qef4C"
      },
      "source": [
        "### nn.Softmax\n",
        "The last linear layer of the neural network returns `logits` - raw values in [-\\infty, \\infty] - which are passed to the\n",
        "[nn.Softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html) module. The logits are scaled to values\n",
        "[0, 1] representing the model's predicted probabilities for each class. ``dim`` parameter indicates the dimension along\n",
        "which the values must sum to 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDPXnqfief4C"
      },
      "outputs": [],
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJd4ZrOmef4C"
      },
      "source": [
        "## Model Parameters\n",
        "Many layers inside a neural network are *parameterized*, i.e. have associated weights\n",
        "and biases that are optimized during training. Subclassing ``nn.Module`` automatically\n",
        "tracks all fields defined inside your model object, and makes all parameters\n",
        "accessible using your model's ``parameters()`` or ``named_parameters()`` methods.\n",
        "\n",
        "In this example, we iterate over each parameter, and print its size and a preview of its values.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5HiNUKsef4C",
        "outputId": "5df4e70b-6099-4e3f-98ed-782ea6255c94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0019,  0.0160, -0.0043,  ..., -0.0193,  0.0066, -0.0297],\n",
            "        [-0.0064,  0.0219,  0.0141,  ..., -0.0344,  0.0129, -0.0208]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0034, -0.0213], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([256, 512]) | Values : tensor([[-0.0031,  0.0279, -0.0315,  ..., -0.0042,  0.0389,  0.0427],\n",
            "        [-0.0257, -0.0376, -0.0101,  ...,  0.0296,  0.0427,  0.0336]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([256]) | Values : tensor([0.0176, 0.0135], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([128, 256]) | Values : tensor([[-1.9947e-02,  4.0868e-02, -5.5166e-02,  4.3511e-02,  4.4130e-02,\n",
            "         -3.6511e-02, -4.3274e-02,  2.0334e-02, -6.3860e-03,  3.3339e-02,\n",
            "          3.4505e-02,  2.6826e-02,  1.3730e-02, -4.6426e-02,  2.9245e-02,\n",
            "          2.0349e-02, -6.2524e-03, -4.6346e-02,  2.2647e-02, -2.0539e-02,\n",
            "          3.2809e-02, -4.0572e-02,  3.6435e-02, -1.4497e-02, -3.9975e-02,\n",
            "          1.2023e-02,  3.1875e-02, -5.9682e-02, -1.6768e-02,  5.2289e-02,\n",
            "          1.9018e-02, -4.4393e-02, -5.0478e-02, -1.6458e-02,  3.5823e-02,\n",
            "         -1.0434e-02,  3.7229e-02,  4.8780e-02,  2.2075e-02,  2.4840e-02,\n",
            "          5.1919e-02,  1.0765e-02, -5.5491e-02,  4.9206e-02,  3.4712e-02,\n",
            "          3.1727e-02, -6.1558e-02, -1.0252e-02, -4.4315e-02,  3.1730e-02,\n",
            "          2.7766e-02,  6.0364e-02,  4.8272e-02, -2.8054e-02, -3.9302e-02,\n",
            "         -4.9459e-02, -6.1230e-02, -8.4059e-03, -5.1472e-02, -5.1109e-02,\n",
            "          2.1440e-02,  3.5172e-02, -1.4820e-02,  4.9204e-02,  1.1324e-02,\n",
            "         -4.3500e-02,  5.4971e-03,  4.9349e-02,  2.3410e-02, -5.5686e-02,\n",
            "          3.0370e-02, -1.8634e-02, -1.4631e-02, -6.1001e-02, -2.1317e-02,\n",
            "         -1.8103e-02,  5.9975e-02,  3.8719e-02,  1.1100e-03, -5.8867e-02,\n",
            "         -5.4100e-02,  6.0188e-02, -2.3016e-02,  5.9094e-02,  1.3356e-02,\n",
            "         -6.0272e-02, -4.8129e-02, -4.4573e-02,  1.6858e-02,  5.2659e-02,\n",
            "         -4.5388e-02,  3.8080e-02,  3.1274e-02,  4.5962e-02,  4.7668e-02,\n",
            "         -1.1176e-02,  2.7888e-02,  3.7580e-02,  1.3165e-02,  2.5026e-02,\n",
            "          6.4000e-03, -4.3392e-02,  1.3443e-02,  5.9871e-02,  2.1531e-02,\n",
            "          5.5690e-03, -3.5692e-02, -4.4886e-02,  5.1552e-02, -1.4768e-02,\n",
            "          5.6714e-02, -5.5856e-02, -2.1559e-02,  1.9652e-03, -5.1353e-02,\n",
            "         -3.2853e-03, -3.6911e-02, -6.0346e-02, -3.9828e-03, -5.0775e-02,\n",
            "          4.7126e-02, -7.9417e-03, -5.5518e-03,  4.8307e-02, -7.1833e-03,\n",
            "         -4.4312e-02,  2.3075e-02,  1.5119e-02,  3.1692e-02, -5.7075e-02,\n",
            "         -5.4938e-04,  5.3727e-02, -4.0320e-02, -1.8835e-02,  4.2879e-02,\n",
            "         -7.9979e-03,  6.1859e-02, -1.0147e-02,  1.7103e-02,  2.6975e-02,\n",
            "         -5.6216e-02, -1.9044e-02, -1.7787e-02,  6.0399e-02,  1.2393e-02,\n",
            "          3.4422e-02, -5.1865e-02, -5.7263e-02,  3.3914e-02,  3.8505e-03,\n",
            "          3.8413e-02, -3.3917e-02,  5.6306e-02,  6.1059e-04,  8.8355e-03,\n",
            "         -5.3741e-02,  1.4425e-02, -2.6714e-02,  4.6661e-02, -4.1203e-02,\n",
            "          2.0234e-02,  2.8340e-02, -1.1317e-02,  2.2592e-02, -5.6528e-02,\n",
            "          4.5819e-02,  3.1883e-02, -5.6293e-02, -2.8612e-02,  1.4912e-02,\n",
            "          3.7073e-02,  3.4223e-02, -4.2796e-02,  2.8855e-02, -3.9543e-02,\n",
            "         -4.1989e-02, -4.1677e-02, -5.3287e-02, -1.3462e-02,  1.1690e-02,\n",
            "         -4.0968e-02,  4.6184e-02, -4.1143e-02,  5.3227e-02,  2.4248e-02,\n",
            "          2.8411e-02,  1.4397e-02,  4.9299e-02,  3.2001e-02,  1.9671e-02,\n",
            "         -2.9983e-03,  4.8169e-02,  6.9677e-03, -5.6437e-02, -5.3941e-02,\n",
            "         -1.3433e-03,  1.0454e-02, -7.4528e-03, -5.3443e-03,  4.6556e-02,\n",
            "          4.5121e-02,  4.7627e-02,  4.5752e-02, -2.2623e-02,  1.4080e-02,\n",
            "          8.9573e-03,  6.1626e-02, -1.7199e-02, -1.4738e-02,  7.1853e-03,\n",
            "         -5.3048e-02,  2.9531e-02,  5.3458e-02,  3.2032e-02,  2.4161e-02,\n",
            "          1.2965e-02,  2.0758e-02,  2.8818e-02,  4.5141e-02,  4.6640e-02,\n",
            "          5.7466e-02, -1.3918e-02, -5.4053e-02, -4.7128e-02, -2.8428e-02,\n",
            "         -2.4787e-02, -6.0740e-02, -4.2301e-03,  2.4498e-02,  5.4817e-02,\n",
            "          6.3862e-03, -3.9810e-02, -5.3663e-02,  3.6342e-02, -4.4885e-03,\n",
            "         -3.9324e-02,  2.1456e-02, -5.5369e-02,  4.3578e-02, -4.6044e-02,\n",
            "         -5.7248e-03, -5.5168e-02, -5.4934e-02, -1.7489e-02, -5.0382e-02,\n",
            "         -5.0167e-03, -5.8850e-02, -4.0475e-02,  4.3961e-02, -4.3464e-02,\n",
            "          1.5347e-02, -3.5488e-03, -3.9696e-02, -4.8369e-02, -3.0835e-02,\n",
            "         -1.3231e-02],\n",
            "        [ 1.4803e-02,  1.5413e-02,  2.7008e-02,  5.7127e-02, -2.9434e-02,\n",
            "         -2.6824e-02,  4.0451e-02, -5.2296e-02,  6.1591e-02, -6.7278e-03,\n",
            "         -5.4457e-02,  5.6929e-02,  5.5714e-02,  7.2932e-03, -5.4699e-02,\n",
            "         -3.7754e-02,  4.4957e-02,  2.4717e-02, -1.2051e-02, -3.8695e-02,\n",
            "         -4.7755e-02,  1.8114e-02, -5.8101e-02, -7.3621e-03,  2.3874e-02,\n",
            "          1.2219e-02, -5.5198e-02,  4.2996e-02, -4.8985e-02, -3.9847e-02,\n",
            "          1.5325e-02,  5.9937e-02, -3.4482e-02,  4.5460e-02, -2.0599e-02,\n",
            "         -2.2507e-02, -4.8413e-02,  8.5386e-03,  1.8611e-03,  2.1132e-02,\n",
            "         -3.4313e-02, -5.8712e-02, -1.6901e-03, -1.1390e-02,  4.2971e-02,\n",
            "          5.8775e-02,  5.2799e-03, -4.2463e-03,  5.1414e-03,  9.6234e-03,\n",
            "          1.7176e-02, -3.5447e-03, -5.6221e-02, -6.2040e-04,  1.3786e-02,\n",
            "         -4.2701e-02, -6.5565e-06,  2.7724e-02,  5.3754e-02,  9.0712e-03,\n",
            "         -5.0774e-02, -3.1456e-02,  5.0382e-02, -4.8312e-02, -6.9306e-03,\n",
            "         -3.5779e-02,  3.3384e-04, -3.8418e-02,  3.6434e-02,  9.9085e-03,\n",
            "          9.3689e-04, -5.7013e-03,  1.3035e-02, -4.7586e-02, -5.7018e-02,\n",
            "         -4.5819e-02, -3.1468e-02,  3.5712e-02, -5.4879e-02, -3.0490e-02,\n",
            "         -3.1022e-02,  8.6487e-03,  2.2332e-02, -4.0693e-03, -4.1551e-04,\n",
            "          2.6873e-02, -2.3704e-02, -5.2243e-05, -4.4299e-03,  4.7435e-02,\n",
            "         -4.9999e-02, -4.7187e-02,  4.9000e-02, -5.4896e-02, -1.0803e-02,\n",
            "         -1.6611e-02,  4.0245e-02,  3.8765e-02,  3.9824e-02, -2.5377e-03,\n",
            "         -1.4482e-02,  2.4852e-02,  4.2004e-02, -5.3427e-02,  5.8892e-02,\n",
            "          5.7355e-02, -5.1261e-02,  1.1136e-02,  2.8044e-02,  1.6506e-02,\n",
            "          2.0182e-02,  1.5761e-03, -2.0198e-02, -2.5530e-02,  1.7738e-02,\n",
            "         -6.6087e-06, -4.6938e-02, -5.8816e-02,  4.0298e-02, -4.3077e-02,\n",
            "         -4.3155e-02, -1.5016e-02,  2.1243e-02, -2.2036e-02, -5.5783e-02,\n",
            "          4.8706e-03, -2.6692e-02,  1.3357e-02,  2.7472e-03, -2.5486e-02,\n",
            "          5.7101e-02,  5.3076e-03, -6.1074e-02,  3.6196e-02,  1.6059e-02,\n",
            "          5.1907e-02,  5.2349e-02,  1.3310e-02, -3.5674e-02,  2.6155e-02,\n",
            "         -1.0662e-02,  2.8982e-02,  3.6528e-02,  2.8156e-02,  1.6749e-05,\n",
            "          4.6092e-02, -6.2557e-03,  5.0012e-02, -2.3816e-02, -2.9816e-02,\n",
            "         -4.0621e-02,  3.0172e-02,  3.7192e-02, -4.2048e-02, -4.1773e-02,\n",
            "         -3.7910e-02, -2.7563e-02, -8.6518e-03,  5.4625e-02,  4.1096e-02,\n",
            "          2.3907e-02,  3.1113e-02,  3.6208e-02, -2.2837e-02,  2.8549e-02,\n",
            "         -4.1589e-02,  2.0339e-02, -1.8097e-03, -2.6435e-02,  4.9714e-02,\n",
            "         -6.0256e-02,  2.4970e-02,  1.2269e-02, -4.8905e-02,  2.6262e-02,\n",
            "         -3.0183e-02,  1.4817e-02,  4.9551e-02,  1.1417e-02,  3.1629e-02,\n",
            "         -5.2096e-02,  5.7000e-02,  3.6545e-02,  1.1886e-02, -2.7300e-02,\n",
            "         -4.9248e-02,  2.1780e-02,  3.0845e-02, -6.0225e-02,  5.5330e-02,\n",
            "         -6.0728e-02, -5.4131e-02, -5.2208e-02, -5.2072e-02, -1.6613e-02,\n",
            "         -4.1081e-02,  4.3492e-02,  2.6239e-02, -2.2181e-02,  1.5961e-04,\n",
            "          1.3558e-02, -6.2868e-03,  3.7761e-02, -1.7532e-04, -1.8456e-02,\n",
            "         -2.7228e-02,  7.9231e-03, -1.1834e-02,  9.4551e-03, -5.7397e-02,\n",
            "          9.7355e-04, -5.7427e-02, -3.8499e-02, -1.2108e-02,  3.5001e-02,\n",
            "          1.0277e-02, -1.3699e-02,  5.6039e-02,  4.0591e-02, -5.4859e-02,\n",
            "          3.5699e-02, -5.3083e-02, -7.9002e-03, -1.4854e-02, -1.7534e-02,\n",
            "          1.2520e-02,  4.3393e-02, -5.1028e-02,  4.9457e-02, -1.0794e-02,\n",
            "          2.9005e-02, -4.3823e-02, -3.3427e-02, -5.4015e-02, -3.1429e-02,\n",
            "         -2.0363e-02,  1.4529e-03,  3.5683e-02, -8.1628e-03, -4.8707e-02,\n",
            "         -2.6695e-02,  2.9859e-02,  4.4159e-02,  2.2841e-02, -5.9025e-03,\n",
            "         -2.7787e-02, -9.8756e-03, -5.8268e-02, -4.5170e-02, -5.8588e-03,\n",
            "         -5.5356e-02, -1.9583e-02,  5.3048e-03, -4.7497e-02, -2.3770e-04,\n",
            "         -2.6087e-02]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([128]) | Values : tensor([-0.0293, -0.0287], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.6.weight | Size: torch.Size([10, 128]) | Values : tensor([[-7.8932e-03, -2.6392e-02,  7.6470e-02,  5.2268e-02,  8.0341e-02,\n",
            "          6.2683e-02, -7.8682e-02,  8.7176e-02, -7.5489e-03,  5.2302e-02,\n",
            "         -4.1552e-02,  2.3384e-02,  3.9690e-02,  1.0217e-02, -9.7102e-03,\n",
            "          4.2354e-02, -3.4996e-02,  6.9873e-02,  6.4513e-03, -4.5363e-02,\n",
            "         -2.9438e-02, -7.3397e-02, -5.5812e-03,  6.4132e-02, -2.8244e-03,\n",
            "         -5.4920e-02, -1.1767e-02, -8.3223e-02, -7.5250e-02, -2.5072e-02,\n",
            "          3.1985e-02,  6.3678e-02, -7.6434e-02, -2.9161e-02, -1.5192e-02,\n",
            "          5.1366e-02, -7.2473e-02,  7.8465e-02, -8.0076e-02, -5.2988e-02,\n",
            "         -7.1424e-02, -7.8868e-02,  8.0083e-02,  7.6248e-02,  1.7180e-03,\n",
            "         -5.7517e-02, -3.2356e-02,  8.5015e-02, -1.7136e-02, -7.8025e-02,\n",
            "         -3.8627e-02,  7.5149e-02, -4.7977e-02, -4.7124e-02,  2.5688e-02,\n",
            "         -1.7868e-02, -5.7171e-02,  7.0057e-02, -8.4516e-02, -8.2355e-03,\n",
            "         -7.4562e-02,  6.6508e-02,  4.9829e-02, -1.2597e-02, -5.6633e-02,\n",
            "         -4.5124e-02, -7.9124e-02,  7.3449e-02,  4.3923e-02, -7.8570e-02,\n",
            "          7.6572e-03,  1.8310e-04,  8.1933e-02, -3.4699e-02, -4.7641e-02,\n",
            "          8.2016e-02, -6.9970e-02, -4.4031e-02, -4.7843e-02, -3.2113e-02,\n",
            "         -8.4529e-02, -1.4105e-02, -4.5194e-03, -5.2128e-02,  3.7927e-02,\n",
            "         -2.9721e-02,  5.0031e-02, -5.4706e-02, -3.8317e-02, -3.5456e-02,\n",
            "         -7.1048e-02,  2.1460e-02,  5.5238e-02,  4.7439e-02,  4.8983e-02,\n",
            "         -1.1971e-03, -4.9757e-02,  6.6234e-02, -7.2462e-02, -3.0626e-02,\n",
            "         -2.1347e-03, -4.1648e-02, -2.8397e-02, -8.0255e-02, -6.0408e-02,\n",
            "         -5.8742e-02, -2.3641e-02, -2.2118e-02,  1.7862e-02,  6.0247e-02,\n",
            "          3.8540e-02,  3.8330e-02,  6.5931e-02,  1.6541e-02, -9.6777e-03,\n",
            "         -8.0613e-02,  1.3163e-02, -7.3243e-02, -8.7683e-02, -3.0780e-02,\n",
            "         -4.2222e-02,  1.6114e-02,  7.3965e-02, -3.5873e-02,  7.5548e-03,\n",
            "          3.0726e-02,  2.9601e-02,  6.8018e-02],\n",
            "        [-3.9239e-02,  5.3556e-02,  5.6266e-02,  6.0881e-02,  7.9077e-02,\n",
            "          6.0114e-02, -3.0386e-02, -4.4266e-02, -3.5588e-02,  7.5726e-02,\n",
            "         -6.5050e-03, -2.6838e-02, -5.1247e-02, -3.0694e-02, -8.6592e-02,\n",
            "         -8.5508e-02,  4.9347e-02, -8.0085e-02, -7.3853e-03, -8.4958e-02,\n",
            "         -2.5012e-02,  3.0661e-02,  6.6964e-02, -4.2460e-02,  7.8201e-02,\n",
            "          8.6998e-02,  5.0933e-02,  6.1719e-02, -7.9549e-02, -7.8286e-02,\n",
            "          3.1293e-02,  1.7771e-02, -3.7312e-02, -2.3422e-02,  6.1125e-02,\n",
            "          6.1831e-02, -2.2379e-03, -3.3925e-02,  5.1821e-02,  3.7538e-02,\n",
            "         -8.1525e-02,  6.7898e-03, -5.0745e-02, -3.4880e-02,  4.6479e-03,\n",
            "          7.7715e-02, -6.9341e-02, -7.3373e-02, -3.4086e-02,  3.0586e-02,\n",
            "          4.3915e-02, -4.4605e-02, -2.6177e-02,  2.2330e-02,  1.7861e-02,\n",
            "         -1.9676e-03, -1.7963e-03, -7.7682e-02, -1.8388e-02, -5.6675e-02,\n",
            "         -7.7809e-02,  1.5282e-02,  8.5393e-02, -4.3459e-02, -2.6045e-02,\n",
            "          7.6667e-02, -3.6637e-02,  1.7217e-05, -5.1309e-02,  2.1314e-02,\n",
            "         -4.0552e-02, -2.2966e-02,  5.1356e-02,  6.9429e-02,  5.3187e-02,\n",
            "         -4.6061e-02, -7.2952e-02, -4.4319e-03, -5.7925e-03, -3.2250e-02,\n",
            "          1.0553e-02, -3.4102e-02,  7.3108e-02,  4.2999e-02,  7.5743e-02,\n",
            "          2.2371e-02, -8.8026e-02,  6.0160e-02,  7.6272e-03, -3.6578e-02,\n",
            "         -3.3788e-02,  1.9202e-02,  4.3544e-02, -4.1739e-02,  7.3051e-05,\n",
            "         -8.4477e-02,  8.4700e-03, -5.8348e-02,  6.1583e-03,  1.8265e-02,\n",
            "         -4.8835e-02,  1.3529e-02, -8.5553e-02,  6.0108e-02, -4.7272e-02,\n",
            "          8.2002e-02, -6.0512e-02, -3.5905e-02, -3.0180e-02, -8.0984e-02,\n",
            "          2.8162e-02, -3.3034e-02,  2.3223e-02,  2.9084e-02,  8.6847e-02,\n",
            "          1.6841e-02,  5.1443e-02, -1.0571e-02, -4.3527e-02,  7.8178e-02,\n",
            "         -1.1638e-02, -6.8380e-04,  3.7026e-02, -6.8639e-02, -1.4789e-02,\n",
            "          8.2517e-03,  3.0563e-02,  1.1406e-02]], device='cuda:0',\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.6.bias | Size: torch.Size([10]) | Values : tensor([0.0818, 0.0327], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Model structure: {model}\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diu7bO4Yef4C"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrINZnUxef4C"
      },
      "source": [
        "## Further Reading\n",
        "- [torch.nn API](https://pytorch.org/docs/stable/nn.html)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}